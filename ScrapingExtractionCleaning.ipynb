{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22ea7b22-b205-48a6-81ad-411a16c6ff62",
   "metadata": {},
   "source": [
    "### Phase 1: Data Scraping, Extraction, Cleaning, and Exporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188e6b19-c1b8-4920-bf09-05656df73e92",
   "metadata": {},
   "source": [
    "In this phase, I scrape the Islamabad, Pakistan air quality data available on Pakistan Environmental Protection Agency website, extract the data from the .pdf files, clean it and export it to .csv files.\n",
    "\n",
    "I divide the scraped .pdfs files by whether or not the files have tables of data or images of the tables of data. The .pdf files that have tables of data are further divided based on whether or not the tabula-py package reads them correctly or not. Each group of files is then separately treated, cleaned, and saved.\n",
    "\n",
    "To read the data from the .pdf files containing images of data, the initial idea was to use pytesseract to read them. However, there were serious issues related to it's accuracy. For example, pytesseract was not accurate in identifying the presence of decimal points in the numbers in the data, leading to genuine data quality concerns. Therefore, I decided to utilize the Google Cloud Vision API which was really accurate as compared to pytesseract.\n",
    "\n",
    "Each of the images of data and the tables extracted from these images are displayed together in this notebook towards the end for manual verification purposes as well. I also export a merged .csv file called \"final_data.csv\" that contains the observations of Islamabad air quality for every month from June, 2019 to March, 2023. A new column named \"Year\" is added in this file to easily distinguish the observations by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895d4ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import fitz\n",
    "import io\n",
    "from PIL import Image\n",
    "import copy\n",
    "import re\n",
    "import requests\n",
    "from lxml import html\n",
    "import camelot\n",
    "import tabula\n",
    "from PyPDF2 import PdfReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99545524",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://environment.gov.pk/Detail/ZjU5NDM3YjItNTdiOS00NTk5LWExYzUtMjI2NzE5YjdlOGM5\"\n",
    "\n",
    "w_page = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3df6700",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = html.fromstring(w_page.content)\n",
    "\n",
    "links = links.xpath('//a/@href')\n",
    "\n",
    "extract_ext = \".pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6de2389",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_links = []\n",
    "\n",
    "for link in links:\n",
    "    if extract_ext in link:\n",
    "        if link not in cleaned_links:\n",
    "            cleaned_links.append(link)\n",
    "cleaned_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab748ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_string_list = [\"2018\", \"May2019\", \"May23\"] \n",
    "\n",
    "filtered_links = copy.deepcopy(cleaned_links)\n",
    "\n",
    "for f in filter_string_list:\n",
    "    for link in cleaned_links:\n",
    "        if f in link:\n",
    "            filtered_links.remove(link)\n",
    "\n",
    "filtered_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441bbbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epa = \"https://environment.gov.pk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56735558",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in filtered_links:\n",
    "    \n",
    "    file_name = re.search('([^\\/]+)\\.pdf$', l)\n",
    "    \n",
    "    file_name = file_name.group(0)\n",
    "    \n",
    "    file_url = epa + l\n",
    "    \n",
    "    \n",
    "    d_file = requests.get(file_url)\n",
    "    \n",
    "    open('{}'.format(file_name), 'wb').write(d_file.content)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ca2c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir()\n",
    "\n",
    "files = [file for file in files if \".pdf\" in file]\n",
    "\n",
    "\n",
    "tablefiles = []\n",
    "imgfiles = []\n",
    "\n",
    "for f in files:\n",
    "    \n",
    "    pdf = fitz.open(f)\n",
    "\n",
    "    page = pdf[0]\n",
    "\n",
    "    images = page.get_images(full=True)\n",
    "    \n",
    "    if images == []:\n",
    "        tablefiles.append(f)\n",
    "    else:\n",
    "        imgfiles.append(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7952ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"extracted_images\"\n",
    "output_frmt = \"png\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6297ce62",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = []\n",
    "\n",
    "for i in imgfiles:    \n",
    "    pdf = fitz.open(i)\n",
    "    name = i.replace(\".pdf\",\"\")\n",
    "    image_names.append(name)\n",
    "\n",
    "    page = pdf[0]\n",
    "\n",
    "    images = page.get_images(full=True)\n",
    "\n",
    "    xref = images[0][0]\n",
    "    \n",
    "    base_image = pdf.extract_image(xref)\n",
    "    image_bytes = base_image[\"image\"]\n",
    "\n",
    "    image = Image.open(io.BytesIO(image_bytes))\n",
    "    image.save(open(os.path.join(output_dir, \"{}.png\".format(name)), \"wb\"), format=output_frmt.upper())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc7ea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in image_names:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f4e795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from img2table.document import Image\n",
    "\n",
    "from img2table.ocr import VisionOCR\n",
    "\n",
    "ocr = VisionOCR(api_key=\"\", timeout=15) # Google Cloud Vision API key\n",
    "\n",
    "for i in image_names:\n",
    "    \n",
    "    extracted_img = Image(\"extracted_images\\\\{}.png\".format(i))\n",
    "    # Table extraction\n",
    "    extracted_img.to_xlsx(dest=\"{}.xlsx\".format(i),\n",
    "                ocr=ocr,\n",
    "                implicit_rows=False,\n",
    "                borderless_tables=False,\n",
    "                min_confidence=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8372130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01c96f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_dfs_list = []\n",
    "\n",
    "readable_files = []\n",
    "\n",
    "incorrectly_read_files = []\n",
    "\n",
    "somewhat_readable = []\n",
    "\n",
    "for tf in tablefiles:\n",
    "    \n",
    "    year = re.search(\"[0-9]+\", tf)\n",
    "    year = year.group(0)\n",
    "    \n",
    "    df_list = tabula.read_pdf(tf, pages=1, pandas_options = {\"header\":None})\n",
    "    table_df = df_list[0]\n",
    "    \n",
    "    if len(table_df.columns.values) < 6:\n",
    "        incorrectly_read_files.append(tf)\n",
    "    elif len(table_df.columns.values) > 6:\n",
    "        somewhat_readable.append(tf)\n",
    "    else:\n",
    "        readable_files.append(tf)\n",
    "        table_df['Year'] = year\n",
    "        table_dfs_list.append(table_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99da91d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(incorrectly_read_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9c4870",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(somewhat_readable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cac1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(table_dfs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0bdd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(readable_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b17f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in table_dfs_list:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d36a491",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"Date\", \"Temperature\", \"Humidity\", \"NO2\", \"SO2\", \"PM2.5\", \"Year\"]\n",
    "\n",
    "cleaned_cr = []\n",
    "\n",
    "for df in table_dfs_list:\n",
    "    if pd.isnull(df[0][0]):\n",
    "        cleaned_df = df.drop(0)\n",
    "        if df[0][1]==\"Date\":\n",
    "            cleaned_df = cleaned_df.drop(1)\n",
    "        if \"NEQS\" in df[0][2]:\n",
    "            cleaned_df = cleaned_df.drop(2)\n",
    "        ext_month = cleaned_df.iloc[7, 0]\n",
    "        month = re.search(\"[A-Za-z]+\", ext_month)\n",
    "        month = month.group(0)\n",
    "        \n",
    "        while 1:\n",
    "            if month not in cleaned_df.iloc[-1, 0]:\n",
    "                cleaned_df = cleaned_df[:-1]\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        cleaned_df.reset_index(drop=True, inplace=True)\n",
    "        cleaned_df.columns = col_names\n",
    "        cleaned_cr.append(cleaned_df)\n",
    "    else:\n",
    "        if df[0][0] == \"Date\":\n",
    "            cleaned_df = df.drop(0)\n",
    "            if \"NEQS\" in df[0][1]:\n",
    "                cleaned_df = cleaned_df.drop(1)\n",
    "            if \"Value\" in df[0][2]:\n",
    "                cleaned_df = cleaned_df.drop(2)\n",
    "            ext_month = cleaned_df.iloc[5, 0]\n",
    "            month = re.search(\"[A-Za-z]+\", ext_month)\n",
    "            month = month.group(0)\n",
    "            cleaned_df = cleaned_df[:-1]\n",
    "            while 1:\n",
    "                if month not in cleaned_df.iloc[-1, 0]:\n",
    "                    cleaned_df = cleaned_df[:-1]\n",
    "                else:\n",
    "                    break\n",
    "            cleaned_df.reset_index(drop=True, inplace=True)\n",
    "            cleaned_df.columns = col_names\n",
    "            cleaned_cr.append(cleaned_df)\n",
    "        else:\n",
    "            cleaned_df = df\n",
    "            cleaned_df.iloc[0,2] = cleaned_df[0][0]\n",
    "            cleaned_df = cleaned_df.drop([0, 1])\n",
    "            ext_month = cleaned_df.iloc[5, 0]\n",
    "            month = re.search(\"[A-Za-z]+\", ext_month)\n",
    "            month = month.group(0)\n",
    "            cleaned_df = cleaned_df[:-1]\n",
    "            while 1:\n",
    "                if month not in cleaned_df.iloc[-1, 0]:\n",
    "                    cleaned_df = cleaned_df[:-1]\n",
    "                else:\n",
    "                    break\n",
    "            cleaned_df.reset_index(drop=True, inplace=True)\n",
    "            cleaned_df.columns = col_names\n",
    "            cleaned_cr.append(cleaned_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a77bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cleaned_cr:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d1752",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in somewhat_readable:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c7e09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_sr = []\n",
    "\n",
    "for s in somewhat_readable:\n",
    "    year = re.search(\"[0-9]+\", s)\n",
    "    year = year.group(0)\n",
    "    \n",
    "    reader = PdfReader(s)\n",
    "    page = reader.pages[0]\n",
    "    string_t = page.extract_text()\n",
    "\n",
    "    string_bytes = io.StringIO(string_t)\n",
    "\n",
    "    df = pd.read_csv(string_bytes, sep = \"\\n\")\n",
    "    df = df[df.columns.values[0]].str.split(\" \", expand=True)\n",
    "    df = df.iloc[:, :6]\n",
    "    \n",
    "    df[\"Year\"] = year\n",
    "    \n",
    "    ext_month = df.iloc[0, 0]\n",
    "    month = re.search(\"[A-Za-z]\", ext_month)\n",
    "    month = month.group(0)\n",
    "    \n",
    "    while month not in df.iloc[-1, 0]:\n",
    "        df = df[:-1]\n",
    "    df.columns = col_names\n",
    "    cleaned_sr.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b20f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in cleaned_sr:\n",
    "    print(s)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e59692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clean_list = cleaned_cr + cleaned_sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97ae48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cleaned_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf6d686",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cleaned_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6e8889",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in incorrectly_read_files:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc85b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_ir = []\n",
    "\n",
    "for i in incorrectly_read_files:\n",
    "    year = re.search(\"[0-9]+\", i)\n",
    "    year = year.group(0)\n",
    "\n",
    "    reader = PdfReader(i)\n",
    "    page = reader.pages[0]\n",
    "    string_t = page.extract_text()\n",
    "\n",
    "    string_bytes = io.StringIO(string_t)\n",
    "\n",
    "    df = pd.read_csv(string_bytes, sep = \"\\n\")\n",
    "    df = df.drop(0)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df = df[:-1]\n",
    "    \n",
    "    ext_month = df.iloc[7, 0]\n",
    "    month = re.search(\"[A-Za-z]\", ext_month)\n",
    "    month = month.group(0)\n",
    "    \n",
    "    \n",
    "    while 1:\n",
    "        if month not in df.iloc[0, 0]:\n",
    "            df = df.drop(0)\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "        else:\n",
    "            break\n",
    "    df.columns = [\"Date Temperature Humidity NO2 SO2 PM2.5\"]\n",
    "    df = df[df.columns.values[0]].str.split(\" \", expand=True)\n",
    "    if len(df.columns.values) == 7:\n",
    "        df = df.drop(6, axis=1)\n",
    "    if len(df.columns.values) > 7:\n",
    "        df[\"hum\"] = df[2] + df[3]\n",
    "        df = df.drop(2, axis=1)\n",
    "        df = df.drop(3, axis=1)\n",
    "        df[\"no2\"] = df[4] + df[5]\n",
    "        df = df.drop(4, axis=1)\n",
    "        df = df.drop(5, axis=1)\n",
    "        df[\"so2\"] = df[6] + df[7]\n",
    "        df = df.drop(6, axis=1)\n",
    "        df = df.drop(7, axis=1)\n",
    "        df[\"pm\"] = df[8] + df[9]\n",
    "        df = df.drop(8, axis=1)\n",
    "        df = df.drop(9, axis=1)\n",
    "        df.replace(\"\", float(\"NaN\"), inplace=True)\n",
    "        df.dropna(how='all', axis=1, inplace=True)\n",
    "\n",
    "    df[\"Year\"] = year\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.columns = col_names\n",
    "    cleaned_ir.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25439898",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cleaned_ir:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1382402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cleaned_ir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55227813",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clean_list = all_clean_list + cleaned_ir\n",
    "len(all_clean_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d7fab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx_files = os.listdir()\n",
    "xlsx_files = [f for f in xlsx_files if \".xlsx\" in f]\n",
    "\n",
    "xlsx_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f8a7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_xlf = []\n",
    "\n",
    "for j in xlsx_files:\n",
    "    t = pd.read_excel(j, header=1)\n",
    "    year = re.search(\"\\d{4}\\.\\w+\", j)\n",
    "    year = year.group(0)\n",
    "    year = year.replace(\".xlsx\", \"\")\n",
    "    t = t.drop(0)\n",
    "    t.reset_index(drop=True, inplace=True)\n",
    "    while 1:\n",
    "        if \"NEQS\" in t.loc[0][0]:\n",
    "            t = t.drop(0)\n",
    "            t.reset_index(drop=True, inplace=True)\n",
    "        elif \"Value\" in t.loc[0][0]:\n",
    "            t = t.drop(0)\n",
    "            t.reset_index(drop=True, inplace=True)\n",
    "        else:\n",
    "            break\n",
    "    t = t[:-1]\n",
    "    t = t.dropna(axis='columns', how='all')\n",
    "    t[\"Year\"] = year\n",
    "    t.columns = col_names\n",
    "    t.reset_index(drop=True, inplace=True)\n",
    "    cleaned_xlf.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f8ca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in cleaned_xlf:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79244e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cleaned_xlf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea78b945",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cleaned_xlf) == len(xlsx_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48904ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clean_list = all_clean_list + cleaned_xlf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2839920",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_clean_list) == len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d3f43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "img_path = \"extracted_images\"\n",
    "\n",
    "disp = os.listdir(\"extracted_images/\")\n",
    "\n",
    "for i in range(len(disp)):\n",
    "    print(\"Image {}:\".format(i+1))\n",
    "    display(Image(img_path + \"/\" +disp[i], width=400))\n",
    "    print(\"Extracted Dataframe {}:\".format(i+1))\n",
    "    print(cleaned_xlf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f667015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_dir = \"extracted_data\"\n",
    "\n",
    "if not os.path.exists(extracted_dir):\n",
    "    os.makedirs(extracted_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dead75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(len(readable_files)):\n",
    "    name = readable_files[c].replace(\".pdf\", \"\")\n",
    "    df = cleaned_cr[c].drop(\"Year\", axis=1)\n",
    "    df.to_csv(os.path.join(extracted_dir, \"{}.csv\".format(name)), index=False)\n",
    "\n",
    "for c in range(len(somewhat_readable)):\n",
    "    name = somewhat_readable[c].replace(\".pdf\", \"\")\n",
    "    df = cleaned_sr[c].drop(\"Year\", axis=1)\n",
    "    df.to_csv(os.path.join(extracted_dir, \"{}.csv\".format(name)), index=False)\n",
    "\n",
    "for c in range(len(incorrectly_read_files)):\n",
    "    name = incorrectly_read_files[c].replace(\".pdf\", \"\")\n",
    "    df = cleaned_ir[c].drop(\"Year\", axis=1)\n",
    "    df.to_csv(os.path.join(extracted_dir, \"{}.csv\".format(name)), index=False)\n",
    "    \n",
    "for x in range(len(xlsx_files)):\n",
    "    name = xlsx_files[x].replace(\".xlsx\", \"\")\n",
    "    df = cleaned_xlf[x].drop(\"Year\", axis=1)\n",
    "    df.to_csv(os.path.join(extracted_dir, \"{}.csv\".format(name)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f101dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = os.listdir(\"extracted_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b7ea4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8c8eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d41582",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_files) == len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f373446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_clean_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614920c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat(all_clean_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f5b488",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"Date\"] = final_df[\"Date\"].str.replace('\\s+', '', regex=True)\n",
    "final_df[\"Date\"] = final_df[\"Date\"].str.replace('-', ' ', regex=True)\n",
    "final_df[\"Date\"] = final_df[\"Date\"].str.replace('\\d{4}', '', regex=True)\n",
    "final_df[\"Date\"] = final_df[\"Date\"].str.replace('^0+(?!$)', '', regex=True)\n",
    "final_df[\"Date\"] = final_df[\"Date\"].str.replace('\\d{2}$', '', regex=True)\n",
    "final_df[\"Date\"] = final_df[\"Date\"].str.rstrip()\n",
    "\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8b016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_df[\"Date\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c364210",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"final_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af36270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
